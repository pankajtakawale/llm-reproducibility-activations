/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:235: UserWarning: 
NVIDIA GB10 with CUDA capability sm_121 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_80 sm_86 sm_90 compute_90.
If you want to use the NVIDIA GB10 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(
ðŸ”¥ Using FULL GPU config (6 layers, 384 hidden, 5000 iters) - Publication Quality
============================================================
RUNNING MULTI-MODEL EXPERIMENTS
============================================================
Device: cuda
Models: convlm (1 total)
Activations: relu, gelu, swish (3 total)
Iterations: 5000, Trials: 3
Total experiments: 1 models Ã— 3 activations = 3
============================================================

############################################################
# MODEL 1/1: CONVLM
############################################################

[1/3] convlm with relu...

############################################################
# EXPERIMENT: RELU
############################################################
[INFO] Loaded 1,115,394 characters from data/shakespeare.txt
[INFO] Train size: 1,003,854 characters
[INFO] Val size: 111,540 characters
[INFO] Vocabulary size: 65
[INFO] Characters: 
 !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz

============================================================
Training Trial 1
============================================================
Starting Trial 1 - 5000 iterations
Step     0 | Train loss: 5.0996 | Val loss: 5.1021 | Time: 65.2s
